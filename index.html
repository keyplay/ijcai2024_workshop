<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>IJCAI 2024 workshop</title>
        <!-- Favicon-->
        <link rel="icon" type="image/x-icon" href="dist/assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.1/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Merriweather+Sans:400,700" rel="stylesheet" />
        <link href="https://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic" rel="stylesheet" type="text/css" />
        <!-- Third party plugin CSS-->
        <link href="https://cdnjs.cloudflare.com/ajax/libs/magnific-popup.js/1.1.0/magnific-popup.min.css" rel="stylesheet" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="dist/css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-light fixed-top py-3" id="mainNav">
            <div class="container">
                <a class="navbar-brand js-scroll-trigger" href="#page-top">IJCAI</a>
                <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ml-auto my-2 my-lg-0">
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#Introduction">Introduction</a></li>
					    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#Dates">Important Dates</a></li>
					    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#topics">Topics</a></li>
					    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#submission">Submission and Registration</a></li>
					    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#schedule">Planed Schedule</a></li>
					    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#committee">Committee</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Masthead-->
        <header class="masthead">
            <div class="container h-100">
                <div class="row h-100 align-items-center justify-content-center text-center">
                    <div class="col-lg-10 align-self-end">
                        <h1 class="text-uppercase text-white font-weight-bold">4th International Workshop on Deep Learning for Human Activity Recognition</h1>
                        <hr class="divider my-4" />
                    </div>
                    <div class="col-lg-9 align-self-baseline">
                        <p class="text-white-75 font-weight-light mb-5">Held in conjunction with IJCAI-24, 3rd â€“ 9th August, 2024 in Jeju, Korea</p>
						<a class="btn btn-primary btn-xl js-scroll-trigger" href="https://sites.google.com/site/zhangleuestc/deep-learning-for-human-activity-recognition">1st workshop</a>
						<a class="btn btn-primary btn-xl js-scroll-trigger" href="https://keyplay.github.io/ijcai2020workshop/">2nd workshop</a>
						<a class="btn btn-primary btn-xl js-scroll-trigger" href="https://keyplay.github.io/ijcai2021_workshop/">3rd workshop</a>
                    </div>
                </div>
            </div>
        </header>
        <!-- Introduction-->
        <section class="page-section" id="Introduction">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="col-lg-8 text-center">
                        <h2 class="section-heading text-uppercase">Introduction</h2>
                          <hr class="divider my-4" />
						</div>
						<p class="text-muted">Human activity recognition (HAR) can be used for a number of applications, such as health-care services and smart home applications. Many sensors have been utilized for human activity recognition, 
						such as wearable sensors, smartphones, radio frequency (RF) sensors (WiFi, RFID), LED light sensors, cameras, etc. Owing to the rapid development of wireless sensor network, a large amount of data has been collected for the recognition of human activities with different kind of sensors. 
						Conventional shallow learning algorithms, such as support vector machine and random forest, require to manually extract some representative features from large and noisy sensory data. However, manual feature engineering requires export knowledge and will inevitably miss implicit features. 
						</p>

						<p class="text-muted">Recently, deep learning has achieved great success in many challenging research areas, such as image recognition and natural language processing. The key merit of deep learning is to automatically learn representative features from massive data. 
						This technology can be a good candidate for human activity recognition. Some initial attempts can be found in the literature. However, many challenging research problems in terms of accuracy, device heterogeneous, environment changes, etc. remain unsolved.  
						</p>

						<p class="text-muted">This workshop intends to prompt state-of-the-art approaches on deep learning for human activity recognition. The organizers invite researchers to participate and submit their research papers in the Deep Learning for Human Activity Recognition Workshop.   
						</p>   
				</div>
                </div>
            </div>
        </section>
        <!-- Dates-->
        <section class="page-section" id="Dates">
            <div class="container">
                <h2 class="text-center mt-0">Important Date</h2>
                <hr class="divider my-4" />
                <div class="row">
                    <div class="col-lg-10 col-md-6 text-center">
						<table class="table table-bordered table-hover white"><tbody> 
						<tr><td>May 9, 2024 <del> April 26, 2024 </del> </td> <td>Submission deadline</td></tr>
						<tr><td>June 4, 2024 <!--<del> July 1, 2021 </del>--> </td> <td>Acceptance notification</td></tr>
						<tr><td>August 3-9, 2024</td> <td>Conference dates</td></tr>
						</tbody></table>
                        <p class="text-muted">As requested by authors, we will extend the submission to May 9 to give more time for authors. The time zone is the same as the main conference.</p>
                    </div>
                </div>
            </div>
        </section>
		<!-- Dates-->
        <section class="page-section" id="topics">
            <div class="container">
                <h2 class="text-center mt-0">Topics</h2>
                <hr class="divider my-4" />
				<p>Potential topics include but are not limited to</p>
                <div class="row">
                    <div class="row text-center">
					    <div class="col-md-4"><p class="text-muted">Foundation models for HAR</p></div>
						<div class="col-md-4"><p class="text-muted">Device-based HAR using deep learning</p></div>
						<div class="col-md-4"><p class="text-muted"> Device-free HAR using deep learning</p></div>
						<div class="col-md-4"><p class="text-muted">Image based HAR using deep learning</p></div>
						<div class="col-md-4"><p class="text-muted">Light sensor based HAR using deep learning</p></div>
						<div class="col-md-4"><p class="text-muted">Sensor fusion for HAR using deep learning</p></div>
						<div class="col-md-4"><p class="text-muted"> Fusion of shallow models with deep networks for HAR</p></div>
						<div class="col-md-4"><p class="text-muted">Device heterogeneous for device-based HAR</p></div>
						<div class="col-md-4"><p class="text-muted"> Transfer Learning for HAR</p></div>
						<div class="col-md-4"><p class="text-muted">Federated Learning for HAR</p></div>
						<div class="col-md-4"><p class="text-muted">Reinforcement Learning for HAR</p></div>
						<div class="col-md-4"><p class="text-muted">Online Learning for HAR</p></div>
						<div class="col-md-4"><p class="text-muted">Self-supervised Learning for HAR</p></div>
						<div class="col-md-4"> <p class="text-muted">Semi-supervised Learning for HAR</p></div>
					</div>
                </div>
            </div>
        </section>
		<section class="page-section" id="submission">
			<div class="container">
			  <div class="row">
				<div class="col-lg-12 text-center"><h2 class="section-heading text-uppercase">Submission and Registration</h2><hr class="divider my-4" /></div>
					<p class="text-muted">Submission Format: The authors should follow IJCAI paper preparation instructions, including page length (e.g. 7 pages + 2 extra page for reference). The paper follows double-blind review.</p>
					<p class="text-muted"><b>At least one author of each accepted paper *must* travel to the IJCAI venue in person, and that multiple submissions of the same paper to more IJCAI workshops are forbidden.</b></p>
					<p class="text-muted">Sign up is required for submission. <a href="https://chairingtool.com/conferences/DLHAR24/MainTrack"> Submission Link</a>.</p>
					<!--<p class="text-muted">IJCAI-20 Registration is open. <a href="https://ijcai20.org/register/">Registration Link</a></p> -->
					<!--
					<p class="text-muted">The authors are invited to submit  papers (6-10+ pages) by emailing to Chen_Zhenghua@i2r.a-star.edu.sg and/or zhangleuestc@gmail.com.</p>
						  <p class="text-muted">Authors should consult Springer's&nbsp;<a href="ftp://ftp.springernature.com/cs-proceeding/svproc/guidelines/Springer_Guidelines_for_Authors_of_Proceedings.pdf" style="font-style:inherit;font-variant:inherit;font-weight:inherit;font-stretch:inherit;line-height:inherit;margin:0px;padding:0px;border-width:0px 0px 1px;border-top-style:initial;border-right-style:initial;border-bottom-style:dotted;border-left-style:initial;border-color:initial;vertical-align:baseline;color:inherit">authors' guidelines</a>&nbsp;and use their proceedings templates, either for&nbsp;<a href="ftp://ftp.springernature.com/cs-proceeding/llncs/llncs2e.zip" style="font-style:inherit;font-variant:inherit;font-weight:inherit;font-stretch:inherit;line-height:inherit;margin:0px;padding:0px;border-width:0px 0px 1px;border-top-style:initial;border-right-style:initial;border-bottom-style:dotted;border-left-style:initial;border-color:initial;vertical-align:baseline;color:inherit">LaTeX</a>&nbsp;or for&nbsp;<a href="ftp://ftp.springernature.com/cs-proceeding/llncs/word/splnproc1703.zip" style="font-style:inherit;font-variant:inherit;font-weight:inherit;font-stretch:inherit;line-height:inherit;margin:0px;padding:0px;border-width:0px 0px 1px;border-top-style:initial;border-right-style:initial;border-bottom-style:dotted;border-left-style:initial;border-color:initial;vertical-align:baseline;color:inherit">Word</a>, for the preparation of their papers. Springer encourages authors to include their ORCIDs in their papers. In addition, the corresponding author of each paper, acting on behalf of all of the authors of that paper, must complete and sign a&nbsp;<a href="https://folk.ntnu.no/andriis/hidamt2019/Contract_Book_Contributor_Consent_to_Publish_CCIS_SIP.pdf" style="font-style:inherit;font-variant:inherit;font-weight:inherit;font-stretch:inherit;line-height:inherit;margin:0px;padding:0px;border-width:0px 0px 1px;border-top-style:initial;border-right-style:initial;border-bottom-style:dotted;border-left-style:initial;border-color:initial;vertical-align:baseline;color:inherit" rel="nofollow">Consent-to-Publish form</a>, through which the copyright for their paper is transferred to Springer.</p><p class="text-muted">All papers will undergoo peer-review before the acceptance decision will be made.</p><p class="text-muted">The authors of accepted papers must guarantee their presence at the workshop for the presentation. At least one author of each accepted paper must register for the conference.</p><p class="text-muted">For the registration, The information can be found on the conference webpage.</p></div>
					-->			  
			</div>
		</section>
		<section class="bg-light page-section" id="schedule">
			<div class="container">
			  <div class="row">
				<div class="col-lg-12 text-center">
				  <h2 class="section-heading text-uppercase">Planed Schedule</h2>
				  <hr class="divider my-4" />
				</div>
			

			  </div>
			  <div class="row"> 
			<p class="section-subheading" style="font-size:30px"> <b>  </b> </p>
			</div>
				  
		  <div class="row">
			<p class="text-muted"> <b>09:00--09:10 </b> <br>Opening Remarks  </b> <br> by organizers </p>   
		  </div>	
				
		  <div class="row">
			<p class="text-muted"> <b>09:10--10:10 </b> <br> Keynote Presentation: (TBD) <br> by
			 Prof. Zhao Guoying (University of Oulu, Finland)<br>  </p> 
		  </div>
		  
          <div class="row">			
			<p class="text-muted"> <b>10:10â€”10:30</b> <br>
			 Oral 1:  Real-Time Human Action Prediction via Pose Kinematics <br> by Niaz Â­Ahmad; Saif Ullah; Jawad Khan; Youngmoon Lee
			  </p>   
			</div>
			
           <div class="row">			
			<p class="text-muted"> <b>10:30--11:00 </b> <br>
			 Tea Break  <br>
			  </p> 
			</div>
			
           <div class="row">			
			<p class="text-muted"> <b>11:00--12:00 </b> <br>
			  Keynote Presentation: (TBD) <br> by Prof. Paul Lukowicz, DFKI, Germany<br> 
			  </p>   
			</div>
			
           <div class="row">			
			<p class="text-muted"> <b>12:00--12:20</b> <br>
			  Oral 2:  Uncertainty Awareness for Unsupervised Domain Adaptation on Human Activity Recognition <br> by Weide Liu; Xiaoyang Zhong; Lu Wang; Jingwen Hou; Yuemei Luo; Jiebin yan; Yuming Fang
			  </p> 
             </div>
			 
			  <div class="row">
			  <p class="text-muted"> <b>12:20--12:40 </b> <br>
			  Oral 3:  Deep Interaction Feature Fusion for Robust Human Activity Recognition <br> by YongKyung Oh; Sungil Kim; Alex Bui
			  </p> </div>
			 
               <div class="row">
			  <p class="text-muted"> <b>12:40--14:00 </b> <br>
			  Lunch <br>
			  </p> </div>
		
		    <div class="row">
			  <p class="text-muted"> <b>14:00--14:20 </b> <br>
			  Oral 4:  COMPUTER: Unified Query Machine with Cross-modal Consistency for Human Activity Recognition<br> by Tuyen Tran; Thao Minh Le; Hung Tran; Truyen Tran
			  </p> </div>
			  
			<div class="row">
			  <p class="text-muted"> <b>14:20--14:40 </b> <br>
			  Oral 5:  How effective are Self-Supervised models for Contact Identification in Videos (Online) <br> by Malitha Gunawardhana; Limalka Sadith; Liel David; Muhammad Haris; Danny Harari
			  </p> </div>

			<div class="row">
			  <p class="text-muted"> <b>14:40--15ï¼š00 </b> <br>
			  Oral 6:  A Wearable Multi-Modal Edge-Computing System for Real-Time Kitchen Activity Recognition <br> by Mengxi Liu; Sungho Suh; Juan Felipe Vargas; Bo Zhou; Agnes GrÃ¼nerbl; Paul Lukowicz
			  </p> </div>
			  
             <div class="row">
			  <p class="text-muted"> <b> 15:00--15ï¼š10 </b> <br> Closing Remarks <br>  by organizers </p>  
			
			 
			 
			<!--<table class="table table-bordered table-hover white"><tbody><tr><td>8:50AM--9:00AM</td> <td>Welcome from Organizers</td></tr> <tr><td>9:00AM--9:20AM</td> <td>Oral 1: Multi-level Human Fall Detection via Pose Motion Estimator
		<br>
		Jiawei Li; Qianggang Ding; Xiyu Yan; Shu-Tao Xia</td></tr>             <tr><td>9:20AM--9:40AM</td> <td>Oral 2: Hierarchically Aggregated Deep Convolutional Neural Networks for Action Recognition
		<br>Le Zhang; Jagan Varadarajan; Yong Pei; Zhenghua Chen</td></tr><tr><td>9:40AM--10:00AM</td> <td>Oral 3: Dynamic Graph Convolutional Networks by Manifold Regularization
		<br>Sichao Fu; Weifeng Liu; Zheng-Jun Zha</td></tr><tr><td>10:00AM--10:30AM</td> <td>Coffee Break
		</td></tr><tr><td>10:30AM--10:50AM</td> <td>Oral 4: Towards Diversity Activity Recognition Via LSTM-CNN Encoder-Decoder Neural Network
		<br>Linlin Guo; Hang Zhang; Chao Wang; Weiyu Guo; Lei Wang; Chuang Li</td></tr><tr><td>10:50AM--11:10AM</td> <td>Oral 5: Action Recognition using Co-trained Deep Convolutional Neural Networks
		<br>Le Zhang; Jagan Varadarajan; Yong Pei</td></tr><tr><td>11:10AM--11:30AM</td> <td>Oral 6: Improving Human Activity Recognition with Data Sources Integration
		<br>Massinissa Hamidi; Aomar Osmani</td></tr></tbody></table> -->
			  </div>
			</div>
		</section>
		<!-- Team -->
  <section class="bg-light page-section" id="committee">
    <div class="container">
      <div class="row">
        <div class="col-lg-12 text-center">
          <h2 class="section-heading text-uppercase">Committee</h2>
          <hr class="divider my-4" />
        </div>
      </div>
      <div class="row"><h3 class="col-lg-12 text-center">General Chairs</h3>
		<div class="col-sm-3">
          <div class="team-member">
            <a href="https://zhenghuantu.github.io/"><h4>Zhenghua Chen</h4></a>
			<a class="d-block" href="mailto:chen_zhenghua@i2r.a-star.edu.sg">chen_zhenghua@i2r.a-star.edu.sg</a>
            <p class="text-muted">Centre for Frontier AI Research, A*STAR, Singapore</p>
          </div>
        </div>
		<div class="col-sm-3">
          <div class="team-member">
			<a href="https://marsyang.site/"><h4>Jianfei Yang </h4></a>
			<a class="d-block" href="mailto:jianfei.yang@ntu.edu.sg ">jianfei.yang@ntu.edu.sg </a>
            <p class="text-muted">Nanyang Technological University, Singapore</p>
          </div>
        </div>
		<div class="col-sm-3">
          <div class="team-member">            
            <a href="https://sites.google.com/site/wumincf/"><h4>Min Wu</h4></a>
			<a class="d-block" href="mailto:wumin@i2r.a-star.edu.sg">wumin@i2r.a-star.edu.sg</a> 
            <p class="text-muted">Institute for Infocomm Research, A*STAR, Singapore</p>          
          </div>
        </div>
		<div class="col-sm-3">
          <div class="team-member">
			<a href="https://sites.google.com/view/sunghosuh/home"><h4>Sungho Suh</h4></a>
			<a class="d-block" href="mailto:sungho.suh@dfki.de">sungho.suh@dfki.de</a>
            <p class="text-muted">DFKI, Germany</p>
          </div>
		</div>
		</div>
	
    <div class="row">
        <h3 class="col-lg-12 text-center">Program Committee</h3>
		<div class="col-sm-3"><div class="team-member"><h4>Vincent Zheng</h4><p class="text-muted">Advanced Digital Sciences Center, Singapore</p></div></div>
        <div class="col-sm-3"><div class="team-member"><h4>Sinno Pan</h4><p class="text-muted">The Chinese University of Hong Kong</p></div></div>
		<div class="col-sm-3"><div class="team-member"><h4>Keyu Wu</h4><p class="text-muted">A*STAR, Singapore</p></div></div>
		<div class="col-sm-3"><div class="team-member"><h4>Bing Li</h4><p class="text-muted">University of New South Wale, Australian</p></div></div>
		<div class="col-sm-3"><div class="team-member"><h4>Jinming Xu</h4><p class="text-muted">Zhejiang University, China</p></div></div>
		<div class="col-sm-3"><div class="team-member"><h4>Yuecong Xu</h4><p class="text-muted">National University of Singapore</p></div></div>
		<div class="col-sm-3"><div class="team-member"><h4>Han Zou</h4><p class="text-muted">Microsoft, USA</p></div></div>
		<div class="col-sm-3"><div class="team-member"><h4>Wei Cui</h4><p class="text-muted">A*STAR, Singapore</p></div></div>
		<div class="col-sm-3"><div class="team-member"><h4>Lu Xiaoxuan</h4><p class="text-muted">University of Edinburg, UK</p></div></div>
		<div class="col-sm-3"><div class="team-member"><h4>Le Zhang</h4><p class="text-muted">University of Electronic Science and Technology of China</p></div></div>
		<div class="col-sm-3"><div class="team-member"><h4>Paul Lukowicz</h4><p class="text-muted">DFKI, Germany</p></div></div>
		<div class="col-sm-3"><div class="team-member"><h4>Bo Zhou</h4><p class="text-muted">DFKI, Germany</p></div></div>
		<div class="col-sm-3"><div class="team-member"><h4>Vitor Fortes Rey</h4><p class="text-muted">DFKI, Germany</p></div></div>
		<div class="col-sm-3"><div class="team-member"><h4>Michael Beigl </h4><p class="text-muted">Karlsruhe Institute of Technology</p></div></div>
        <div class="col-sm-3"><div class="team-member"><h4>Stephan Sigg </h4><p class="text-muted">Aalto University</p></div></div>
	</div>
        <h3><p class="text-muted">Co-organizer</p></h3>
        <img class="ratio" src="dist/assets/img/sensor_tag.png" alt="cannot find"> 
        </div>
	</section>
        
        

        <!-- Bootstrap core JS-->
        <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/magnific-popup.js/1.1.0/jquery.magnific-popup.min.js"></script>
        <!-- Core theme JS-->
        <script src="dist/js/scripts.js"></script>
    </body>
</html>
